import { StudentConfig } from '../IBDA_config';

export const getChapter1Text = (c: StudentConfig) => {
  const t = {
    1: { // 张明 - 详细描述
      bg: `随着工业4.0战略的深入实施，制造业正经历着从自动化向智能化转型的关键时期。在这一进程中，工业物联网（IIoT）设备的广泛应用产生了海量的时序数据。这些数据中蕴含着设备运行状态、环境参数以及潜在故障模式等宝贵信息。然而，传统的数据处理方式往往基于单机系统或简单的关系型数据库，面对TB级甚至PB级的数据洪流时，显现出存储瓶颈、计算能力不足以及响应延迟高等问题。特别是在铣床加工等精密制造领域，设备故障往往具有突发性和隐蔽性，若不能及时发现并预警，将导致生产线停机、产品质量下降甚至严重的生产安全事故。因此，构建基于Hadoop生态系统的大数据处理平台，实现对海量工业数据的清洗、存储和深度挖掘，已成为提升企业竞争力的核心手段。本实验正是基于这一背景，选取了典型的铣床加工场景，利用真实传感器数据进行全流程的大数据分析实践。`,
      purpose: `本作业的主要目的是构建一个端到端的工业大数据分析系统，旨在解决工业场景下"数据存不下、算不动、看不清"的三大难题。具体学习目标包括：
1. **掌握分布式存储技术**：通过部署和使用HDFS及HBase，理解列式存储与行式存储的区别，掌握RowKey设计原则，解决海量时序数据的高并发写入与即席查询问题。
2. **精通数据预处理流程**：熟练运用Linux Shell工具链（awk, sed, grep）对原始CSV数据进行清洗，处理缺失值、异常值及格式不统一问题，为后续分析奠定高质量数据基础。
3. **深入理解MapReduce编程模型**：编写自定义MapReduce程序，实现对散热系统故障（HDF）等特定模式的离线统计分析，理解Shuffle过程中的排序与分组机制。
4. **提升数据可视化能力**：将枯燥的统计结果转化为直观的图表，能够从数据中识别出L型设备维护周期短、散热系统易失效等关键业务洞察。`,
      route: `本实验的技术路线遵循大数据处理的经典"Lambda架构"思想，分为批处理层和展示层。
第一阶段为**数据采集与增强**。我们从UCI机器学习库获取基础数据集，并编写Python脚本生成符合正态分布的模拟增量数据，模拟真实工厂中多条产线并发上传的场景。
第二阶段为**数据预处理**。利用Linux强大的文本处理能力，编写Shell脚本对数据进行过滤和转换，剔除无效记录，统一字段格式，生成Cleaned Dataset。
第三阶段为**分布式存储**。将清洗后的数据上传至HDFS，并根据查询需求设计HBase表结构，利用BulkLoad方式将数据导入HBase，构建数据仓库。
第四阶段为**离线计算**。基于Hadoop MapReduce框架，开发Java程序对故障类型进行聚合统计，计算不同工况下的故障频率。
第五阶段为**可视化展示**。提取分析结果，利用前端图表库生成柱状图和饼图，形成最终的分析报告。`
    },
    2: { // 李华 - 简洁概括
      bg: `工业互联网的普及使得设备数据呈现爆炸式增长，传统的单机处理模式已无法满足需求。预测性维护（Predictive Maintenance）作为工业大数据的核心应用场景，能够有效降低非计划停机时间。本次实验基于Hadoop生态圈，旨在解决海量传感器数据的存储与计算瓶颈，探索负载水平与设备故障之间的关联。`,
      purpose: `1. **架构部署**：搭建高可用的Hadoop集群，配置HBase分布式数据库。
2. **数据治理**：实现从非结构化CSV文件到结构化NoSQL表的ETL过程。
3. **计算分析**：利用MapReduce并行计算框架，量化分析不同负载等级（轻/中/重）下的设备故障率。
4. **决策支持**：通过可视化手段展示分析结果，为制定差异化的设备维护策略提供数据支撑。`,
      route: `技术栈选用：Linux Shell + HDFS + HBase + MapReduce。
1. **源数据**：UCI AI4I 2020数据集 + 700条增量模拟数据。
2. **ETL层**：使用Shell脚本清洗脏数据，通过 \`hbase importtsv\` 工具批量加载至HBase表 \`industrial_maintenance\`。
3. **计算层**：编写MapReduce作业，Mapper阶段提取Type和Load_Level，Reducer阶段汇总故障次数。
4. **应用层**：生成横向柱状图，直观展示各类故障的分布情况。`
    },
    3: { // 王芳 - 技术分析
      bg: `在智能制造领域，设备运行数据的"3V"特性（Volume, Velocity, Variety）对数据架构提出了严峻挑战。本项目旨在验证NoSQL数据库（MongoDB）与分布式文件系统（HDFS）在处理异构工业数据时的性能优势。特别关注温度梯度（Air Temp与Process Temp之差）对精密加工设备稳定性的影响，通过构建数据管道实现故障模式挖掘。`,
      purpose: `本项目旨在达成以下技术目标：
- **存储优化**：对比关系型数据库，验证MongoDB文档模型在处理Schema-less工业传感器数据时的灵活性与水平扩展能力。
- **算法实现**：掌握MapReduce编程范式，实现自定义Partitioner与Combiner，优化大规模数据集下的统计任务性能。
- **特征工程**：评估"温差风险指数"（Temperature_Risk）作为预测性特征的有效性，量化其与OSF（过载故障）的相关性。
- **全栈实践**：打通从数据摄取、清洗、存储到分析可视化的全链路，构建可复用的工业大数据分析框架。`,
      route: `系统架构采用分层设计：
1. **基础设施层**：基于Ubuntu Linux构建伪分布式Hadoop集群与MongoDB分片集群。
2. **数据接入层**：通过Wget获取UCI数据集，利用Python脚本注入带有特定分布特征的异常流量数据。
3. **数据处理层**：使用Linux管道命令（Pipe）实现流式预处理；利用MongoDB的Aggregation Pipeline或Hadoop MapReduce进行离线批处理。
4. **分析展示层**：重点分析OSF、PWF与HDF三种故障模式，采用Matplotlib风格的图表库进行多维数据展示。`
    },
    4: { // 赵强 - 实践应用
      bg: `厂里的设备老是坏，修起来又贵又慢。这次作业就是想试试能不能用大数据的办法，提前算出机器什么时候会出毛病。我们用的是一套真实的铣床加工数据，加上我自己模拟的一些新数据，主要想看看机器的效率评分（Efficiency_Score）跟故障有没有关系，能不能帮厂里省点钱。`,
      purpose: `这次作业主要想学会这么几招：
1. **数据怎么存**：学会把几万条甚至几亿条数据存到MongoDB里，别像Excel那样打开就卡死。
2. **数据怎么洗**：有些数据是乱码或者空的，得学会用命令把它洗干净，不然算出来的结果是错的。
3. **故障怎么算**：写个程序，自动算出哪些型号的机器最容易坏，是过载坏的多还是散热不行。
4. **图表怎么画**：做几个好看的图，一眼就能看出L型机器是不是不仅效率低还容易坏，给老板汇报用。`,
      route: `做法挺直接的：
第一步，先把数据搞到手，把我自己造的800条数据加进去，凑个整。
第二步，在Linux黑框框里敲命令，把坏数据删了，把有用的挑出来。
第三步，把数据导进MongoDB，这个数据库存这种乱七八糟的数据最方便。
第四步，让电脑自己跑MapReduce程序，帮我数数每种故障发生了多少次。
第五步，最后画个堆叠柱状图，看看不同机器的毛病都分布在哪儿。`
    }
  };
  return t[c.id];
};
